Here is our workbench page, here we can make graphs and anaylse the data trends

```{r setwrk}

#setwd("~/Desktop/MA415/ma4615-fa22-final-project-the_a_team")

```


This section is for cleaning and analyzing the food loss data:

```{r table, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}

suppressPackageStartupMessages(library(tidyverse))
library(readr)


Food_waste <- read_csv(here::here("dataset", "FoodLossandWasteAllClean.csv"))
#View(Food_waste)
head(Food_waste)
```

```{r plots, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
library(plotly)
# plotting food_waste before cleaning up the data
plot1 <- 
  ggplot(Food_waste, aes(x = year, y = mean_loss_percentage, color = country)) +
  geom_point(alpha = 0.3)+ geom_smooth(size=0.5, se = FALSE) + #se = false, is to remove the confidence bands
    ggtitle("Proportion of food waste since 1970") +
    xlab("Year") + ylab("Food waste by percentage")  #+ labs(color = "commodity")

p1 <- plot1 + guides(color = FALSE)#+ scale_x_continuous(, 10)
#plot_ly(Food_waste,  x = ~year, y = ~mean_loss_percentage, color = ~country ) %>% add_markers()

plotly::ggplotly(p1)
```

Figure one, shows the data as it is, and the second graph shows the data after cleaning out the duplicates.

```{r heatmapfoodwastebycountry}
library(maps)
worlddata <- select(fw1, c('year','country','mean_loss_percentage'))
worlddata <- worlddata %>% filter(year > 2009 )

worlddata <- worlddata %>% group_by(year,country) %>% summarise_each(funs(sum))

worlddata <- worlddata %>% group_by(country) %>% summarise_each(funs(mean))

world_map <- map_data("world")
mydata<-worlddata
mydata$country[mydata$country == "United States of America"] <- "USA"
mydata$country[mydata$country == "Russian Federation"] <- "Russia"
world_map <- map_data("world")
world_map <- subset(world_map, region != "Antarctica")

ggplot(mydata) +
  geom_map(
    dat = world_map, map = world_map, aes(map_id = region),
    fill = "white", color = "#7f7f7f", size = 0.25
  ) +
  geom_map(map = world_map, aes(map_id = country, fill = mean_loss_percentage), size = 0.25) +
  scale_fill_gradient(low = "#fff7bc", high = "#cc4c02", name = "Mean Loss of Food Waste") +
  expand_limits(x = world_map$long, y = world_map$lat)

world_map
```

This section is for loading and analyzing the food production data:

```{r food_production, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}

suppressPackageStartupMessages(library(tidyverse))
library(readr)

Food_production <- read_csv(here::here("dataset_ignore", "Food_production_clean.csv"))
#View(Food_production)
head(Food_production)
```

```{r normalizing, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
 fp1 <- Food_production %>% group_by(Item, Year, Value, Unit) #%>%
#    summarise(mean_loss_percentage = mean(loss_percentage))
  #summarise(commodity = sum(commodity))
   
head(fp1)

```

```{r plot_foodprod, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
# plotting food_waste after cleaning up the duplicates from the data
ggplot(fp1, aes(x = Year, y = Area)) +
 geom_point(alpha = 0.3)+ geom_smooth(size=0.5, se = FALSE) #+ #se = false, is to remove the confidence bands
#   ggtitle("Proportion of food production") +
#   xlab("Year") + ylab("Food Production by weight") + theme(axis.text = element_text(size = 2)) 
```



## GDP Dataset:

```{r Loading}
#GDP
GDP <- read_csv(here::here("dataset", "GDP_data_clean.csv"))

#AgriPercentageGDP
AgriGDP <- read_csv(here::here("dataset", "AgriGDP_data_clean.csv"))

#LandPercentage
AgriLand <- read_csv(here::here("dataset", "AgriLand_data_clean.csv"))
#Population
Population <- read_csv(here::here("dataset", "Population_data_clean.csv"))

```

```{r}
ggplot(GDP, aes(x = 2021, y = "Country Name")) + geom_bar()
```

# MODEL Testing
```{r}
library(car)
model1 <- lm(Loss ~ Production, data = AggData)
summary(model1)

model2 <- lm(Loss ~ Year + GDP + AgriGDP + AgriLand + Population + Production, data = AggData)
summary(model2)
(beta <- coef(model2))

avPlots(model2)

```

