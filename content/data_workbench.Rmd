Here is our workbench page, here we can make graphs and anaylse the data trends

```{r setwrk}

#setwd("~/Desktop/MA415/ma4615-fa22-final-project-the_a_team")

```


This section is for cleaning and analyzing the food loss data:

```{r table, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}

suppressPackageStartupMessages(library(tidyverse))
library(readr)

Food_waste <- read_csv("C:/Users/jonat/Documents/GitDataSciPath/ma4615-fa22-final-project-the_a_team/dataset/FoodLossandWasteAll.csv")
#View(Food_waste)
head(Food_waste)
```

```{r cleaning, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}

#In this block we can start cleaning the data until is ready for the ggpplots in another section
# with this, the unnecessary columns have been taken out
  #Food_waste$m49_code <- NULL 
  #Food_waste$country <- NULL 
  #Food_waste$region <- NULL
  #Food_waste$loss_percentage_original <- NULL
  Food_waste$activity <- NULL
  Food_waste$treatment <- NULL
  Food_waste$cause_of_loss <- NULL
  Food_waste$sample_size <- NULL
  Food_waste$method_data_collection <- NULL
  Food_waste$reference <- NULL
  Food_waste$url <- NULL
  Food_waste$notes <- NULL
  Food_waste$loss_quantity <- NULL
```

```{r normalizing, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
fw1 <- Food_waste %>% group_by(year,country,commodity) %>%
   summarise(mean_loss_percentage = mean(loss_percentage))
  #summarise(commodity = sum(commodity))
   
Food_waste

```

```{r plots, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}

# plotting food_waste before cleaning up the data
ggplot(Food_waste, aes(x = year, y = loss_percentage)) +
geom_point(alpha = 0.3)+ geom_smooth(size=0.5, se = FALSE) + #se = false, is to remove the confidence bands
  ggtitle("Proportion of food waste since 1970") +
  xlab("Year") + ylab("Food waste by percentage")  + labs(color = "commodity")

# plotting food_waste after cleaning up the duplicates from the data
ggplot(fw1, aes(x = year, y = mean_loss_percentage)) +
geom_point(alpha = 0.3)+ geom_smooth(size=0.5, se = FALSE) + #se = false, is to remove the confidence bands
  ggtitle("Proportion of food waste since 1970") +
  xlab("Year") + ylab("Food waste by percentage")  + labs(color = "commodity")

# box plot for food_waste
#fw1 %>% 
  #ggplot(aes(mean_loss_percentage, commodity)) + 
  #geom_boxplot() + theme(axis.text = element_text(size = 4)) 



```


```{r heatmapfoodwastebycountry}
library(maps)
mydata2 <- select(fw1, c('year','country','mean_loss_percentage'))
mydata2 <- mydata2 %>% filter(year > 2009 )

#mydata2 <- aggregate(cbind(mydata2$mean_loss_percentage),by=list(year=mydata2$year,country=mydata2&country), FUN=sum)
mydata2
mydata2 <- mydata2 %>% group_by(year,country) %>% summarise_each(funs(sum))
mydata2
mydata2 <- mydata2 %>% group_by(country) %>% summarise_each(funs(mean))
#mydata2 <- mydata2 %>% group_by(country) %>% summarise_each(funs(sum)) 
mydata2
#sd <- order(mydata2$mean_loss_percentage,decreasing = TRUE)

#sd<- data[order(mydata2$mean_loss_percentage, decreasing = TRUE), ]
#sd

#mydata <- data.frame(Country,Cases)
#mydata
world_map <- map_data("world")
mydata<-mydata2
mydata$country[mydata$country == "United States of America"] <- "USA"
mydata$country[mydata$country == "Russian Federation"] <- "Russia"
world_map <- map_data("world")
world_map <- subset(world_map, region != "Antarctica")

ggplot(mydata) +
  geom_map(
    dat = world_map, map = world_map, aes(map_id = region),
    fill = "white", color = "#7f7f7f", size = 0.25
  ) +
  geom_map(map = world_map, aes(map_id = country, fill = mean_loss_percentage), size = 0.25) +
  scale_fill_gradient(low = "#fff7bc", high = "#cc4c02", name = "Mean Loss") +
  expand_limits(x = world_map$long, y = world_map$lat)

world_map
```

Figure one, shows the data as it is, and the second graph shows the data after cleaning out the duplicates.


This section is for cleaning and analyzing the food production data:

```{r food_production, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}

suppressPackageStartupMessages(library(tidyverse))
library(readr)

Food_production <- read_csv("~/Desktop/MA415/ma4615-fa22-final-project-the_a_team/dataset-ignore/Production_All(Normalized).csv")
#View(Food_waste)
head(Food_production)
```

```{r cleaning, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=TRUE}

#In this block we can start cleaning the data until is ready for the ggpplots in another section
# with this, the unnecessary columns have been taken out
  #Food_production$`Domain Code` <- NULL 
  #Food_production$Domain <- NULL 
  #Food_production$`Area Code (M49)` <- NULL
  #Food_production$Area <- NULL
  #Food_production$Element <- NULL
  Food_production$`Item Code (CPC)`<- NULL
  Food_production$`Year Code` <- NULL
  Food_production$Flag <- NULL
  Food_production$`Flag Description`<- NULL
 
```

```{r normalizing, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=TRUE}
fp1 <- Food_production %>% group_by(Item, Year, Value, Unit) #%>%
   #summarise(mean_loss_percentage = mean(loss_percentage))
  #summarise(commodity = sum(commodity))
   
head(fp1)

```

```{r plot_foodprod, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=TRUE}
# plotting food_waste after cleaning up the duplicates from the data
ggplot(fp1, aes(x = Year, y = Item)) +
geom_point(alpha = 0.3)+ geom_smooth(size=0.5, se = FALSE) + #se = false, is to remove the confidence bands
  ggtitle("Proportion of food production") +
  xlab("Year") + ylab("Food Production by weight") + theme(axis.text = element_text(size = 2)) 
```

```{r data}

FdpN <- read_csv("~/Desktop/MA415/ma4615-fa22-final-project-the_a_team/dataset-ignore/Production_All(Normalized).csv")

head(FdpN)
```

```{r Cleaning}
# Datasets cleaning: GDP, AgriPercentageGDP, LandPercentage, and Population

#GDP
GDP <- read_csv("~/Documents/01. Academic/05. Boston 22-23'/MA415/ma4615-fa22-final-project-the_a_team/dataset/GDP.csv", col_types = cols(`[1961:2021]` = col_double()))
GDP <- GDP[-c(1, 2, 4)]

#AgriPercentageGDP
AgriGDP <- read_csv("~/Documents/01. Academic/05. Boston 22-23'/MA415/ma4615-fa22-final-project-the_a_team/dataset/AgriPercentageGDP.csv", col_types = cols(`[1961:2021]` = col_double()))
AgriGDP <- AgriGDP[-c(1, 2, 4)]

#LandPercentage
AgriLand <- read_csv("~/Documents/01. Academic/05. Boston 22-23'/MA415/ma4615-fa22-final-project-the_a_team/dataset/LandPercentage.csv", col_types = cols(`[1961:2021]` = col_double()))
AgriGDP <- AgriGDP[-c(1, 2, 4)]

#Population
Population <- read_csv("~/Documents/01. Academic/05. Boston 22-23'/MA415/ma4615-fa22-final-project-the_a_team/dataset/population.csv", col_types = cols(`[1961:2021]` = col_double()))
Population <- Population[-c(1, 2, 4)]

```

