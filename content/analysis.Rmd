---
title: "Analysis"
description: null
toc: yes
featuredVideo: null
featuredImage: null
draft: no
---

## Rubric: On this page

you will


* Introduce what motivates your Data Analysis (DA)
  * Which variables and relationships are you most interested in?
  * What questions are you interested in answering?
 
  The world population just break through 8 billion recently. According to World Food Programme, around 828 million of people go to bed hungry every night all around the world and more than 49 million people in 49 countries are facing famine crisis.  Our team is interested in exploring the relationships between food supply, food waste, GDP, population density and available land for agriculture among different countries. Furthermore, we are looking forward to explore potential opportunities to mitigate food-waste and calculate world food availability for our current population density.  
  
  As such, we aim to examine the relationship of food security on a worldwide scale using several macro indicators to better understand factors that contribute to food waste. The main variables that we have built our model on are Food Production, GDP, Agriculture as Percentage of GDP, Land Used for Agriculture, Population, and Regions/Continents. One of the primary focuses of our analysis is to look into how food waste may differ by regions and the factors driving the disparity. Therefore, we have selected variables that can, to an extent, provide insight on characteristics of a region. 

Some of the hypotheses driving our analysis can be seen below:
  GDP is a relatively effective signal of a country’s development; thus,  “The developed regions waste a greater percentage of food”. 
  “The greater quantity of food production, the greater amount of food waste percentage”
  “The greater percentage of agriculture as GDP, the greater amount of food wasted” 

While our analysis is quantitatively-driven, …

  
```{r int, echo=TRUE, paged.print=TRUE}
library(tidyverse)
print(getwd())
FoodLossandWasteAllClean <- read_csv(here::here("dataset/FoodLossandWasteAllClean.csv"))
load(here::here("dataset/FoodLossandWasteAllClean.RData"))
print(ls())

```

US have the most "over 40% food loss per commodity per year" up to today, which is around two times the amount Mexico have. It is unimaginable how some commodity lose almost of its amount during production & retail process. We want to look deeper into which commodity are incurring the most loss in US and if there is any reason behind it.

```{r 1, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
FoodLossandWasteAllClean %>%
  select(country,commodity, mean_loss_percentage)%>%
  filter(mean_loss_percentage >= 40)%>%
  group_by(country) %>%
  summarise(count=n()) %>%
  filter(count > 5)%>%
  ggplot(aes(x = country, y =count))+
  geom_col()


```

The following graph indicates that in the US, Pineapple juice, Orange juice and grapefruit juice have been wasted the most over the past decades. One commonality between the most-wasted-commodity is that they are all juice. We may want to explore where did most of the waste occur in the production & retail process of these juice.

```{r 2, echo=TRUE}
FoodLossandWasteAllClean %>%
  select(country,commodity, mean_loss_percentage)%>%
  filter(country == 'United States of America', mean_loss_percentage >= 40) %>%
  group_by(commodity) %>%
  summarise(count = n()) %>%
  filter(count >=3)%>%
  arrange(count)%>%
  ggplot(aes(x = commodity, y = count))+
  geom_col()
```
The following graph explore the sum food waste per year in the United States. In 2008, US incurred the most amount of food waste in the past five decades. A possible explanation for this severe food waste year is that during the depression, a lot of food are wasted because a lot of retailer and food processor went out of business. We may need more data to back up our hypothesis.


```{r 3, echo=TRUE}
FoodLossandWasteAllClean %>%
  select(year,country,commodity, mean_loss_percentage)%>%
  filter(country == 'United States of America') %>%
  group_by(year) %>%
  summarise(sum_loss_per_year = sum(mean_loss_percentage))%>%
  ggplot(aes(x = year, y = sum_loss_per_year))+
  geom_line()
```
The following data further explore the most wasted food in US. Besides from juice, we observe that Canned mushrooms, Tomatoes and Spinach are also among the highest wasted food in the US.  

```{r 4, echo=TRUE, paged.print=TRUE}
FoodLossandWasteAllClean %>%
  select(year,country,commodity, mean_loss_percentage)%>%
  filter(country == 'United States of America') %>%
  group_by(commodity) %>%
  summarise(sum_loss_per_year = sum(mean_loss_percentage))%>%
  arrange(desc(sum_loss_per_year))
```

* Breadth of the DA
  * Make sure that you ask enough initial questions to explore the different variables in your data.
  * i.e. Do you explore more than just one or two variables? Do you explore a few different relationships or many?
  
Our whole analysis revolved around food waste loss in different countries over time. Therefore, not only can we focus on food waste loss in a single year, but also food waste within a span. Therefore our questions are based around this concept:
  Has food waste decreased/increased over time?
  Is there a relationship between a country’s GDP and food waste ? 
  Are there specific countries that are outliers (waste much more/less food than everyone else)
  What is the projected food waste loss for a specific region in 2023?
  
* Depth of the DA
  * When you answer one question, usually more questions arise as well. 
  * The depth of the DA is about coming up with and exploring the answers to these questions, often iterating the process a few times.
  
Answering these questions may seem simple at first glance, but as it turns out, there are a bunch of countries in the world. In order to be able to compare all of the different countries’ food loss within a certain timeframe, we want to be able to display the data in a simple user-friendly manner. For this, we could plot every country in a heatmap. To see whether food loss has decreased over time worldwide, we could do a geom dot plot with a geom line to see the relationship.

* Modeling and Inference 
  * You should also include some kind of formal statistical model and/or inference. This could be a linear regression, logistic regression, hypothesis testing etc.
  * Explain the techniques you used for validating your results.
  * Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.
  
Model/Inference currently a work in progress
  
* Explain the flaws and limitations of your analysis
  * Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions? ...
  
One assumption that we initially made was that our food waste dataset held data for every country and every year. We were first proven wrong when we realized that some countries ceased to exist or began existing throughout the time period recorded. Also, there are years in which some countries may be missing data. This is due to the fact that the way our data was initially collected by the FAO (Food and Agriculture Org) was basically by going through old documents that the country may have provided. This does not work when countries do not really prioritize collecting this information.
  
* Clarity Figures
  * Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?
  * Each figure should provide a key insight. Too many figures or other data summaries can detract from this.
  
We believe that our graphs are actually quite easy to glance at. While making these graphs, we wanted to design them in a way that they could possibly be the first iteration of something that can be used in the “interactive” part of this project. For example, the heatmap we made at the beginning quickly helped us understand which country was a “problem” when it came to food waste.
  
* Clarity of Explanations
  * Do you introduce why you are doing each analysis?
  * How well do you explain each figure/result?
  * Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?
* Organization and cleanliness.
  * Make sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.
  
  
**NOTE**: Your Data Analysis can be broken up into multiple pages if that helps with your organization.